{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8f16d3",
   "metadata": {},
   "source": [
    "# XGBoost for Classification Problem\n",
    "Dataset: `Case_Data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb4d61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rkisyula\\appdata\\local\\anaconda3\\envs\\ticket_ui\\lib\\site-packages (from xgboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rkisyula\\appdata\\local\\anaconda3\\envs\\ticket_ui\\lib\\site-packages (from xgboost) (1.16.1)\n",
      "Downloading xgboost-3.0.4-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/56.8 MB 5.2 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.8/56.8 MB 5.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.9/56.8 MB 5.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 4.2/56.8 MB 5.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 5.5/56.8 MB 5.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 6.6/56.8 MB 5.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 7.9/56.8 MB 5.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 9.2/56.8 MB 5.9 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 10.2/56.8 MB 5.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 11.5/56.8 MB 5.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 12.8/56.8 MB 5.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 13.9/56.8 MB 5.9 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 15.2/56.8 MB 5.9 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 16.3/56.8 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 17.6/56.8 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 18.9/56.8 MB 5.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 20.2/56.8 MB 5.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 21.2/56.8 MB 5.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 22.5/56.8 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 23.9/56.8 MB 5.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 24.9/56.8 MB 5.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 26.2/56.8 MB 5.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 27.0/56.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 27.5/56.8 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 27.8/56.8 MB 5.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 29.4/56.8 MB 5.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 30.4/56.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 31.5/56.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 32.8/56.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 33.8/56.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 35.1/56.8 MB 5.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 36.4/56.8 MB 5.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 37.5/56.8 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 38.8/56.8 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 40.1/56.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 41.2/56.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 42.5/56.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 43.8/56.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 44.8/56.8 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 46.1/56.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 47.2/56.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 48.5/56.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 49.8/56.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 51.1/56.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 52.2/56.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.5/56.8 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.8/56.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  55.6/56.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4850a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling\n",
    "# train_test_split:   splits data into training and testing subsets\n",
    "# KFold:              defines cross-validation folds (e.g., 5-fold CV)\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Pipeline:           chains preprocessing steps (scaling, encoding, model) into one object\n",
    "#                     ensures consistent transformations during training and prediction\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#GridSearchCV:     provides the cv engine for trees which do not have one built in\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics:               roc_auc_score gives a single number (AUC) to summarize model performance\n",
    "#                        roc_curve gives the points to plot the ROC curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#!pip install xgboost if not installed\n",
    "from xgboost import XGBClassifier\n",
    "# Reproducibility seeds\n",
    "np.random.seed(87)  # used for train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52afb6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 68)\n",
      "              TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
      "count   20000.000000              20000       20000        20000   \n",
      "unique           NaN                  2           2            2   \n",
      "top              NaN         Cash loans           F            N   \n",
      "freq             NaN              18089       13189        13213   \n",
      "mean        0.077450                NaN         NaN          NaN   \n",
      "std         0.267311                NaN         NaN          NaN   \n",
      "min         0.000000                NaN         NaN          NaN   \n",
      "25%         0.000000                NaN         NaN          NaN   \n",
      "50%         0.000000                NaN         NaN          NaN   \n",
      "75%         0.000000                NaN         NaN          NaN   \n",
      "max         1.000000                NaN         NaN          NaN   \n",
      "\n",
      "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT  \\\n",
      "count            20000  20000.000000      2.000000e+04  2.000000e+04   \n",
      "unique               2           NaN               NaN           NaN   \n",
      "top                  Y           NaN               NaN           NaN   \n",
      "freq             13973           NaN               NaN           NaN   \n",
      "mean               NaN      0.415450      1.684530e+05  5.981280e+05   \n",
      "std                NaN      0.723103      1.152069e+05  4.033457e+05   \n",
      "min                NaN      0.000000      2.610000e+04  4.500000e+04   \n",
      "25%                NaN      0.000000      1.125000e+05  2.700000e+05   \n",
      "50%                NaN      0.000000      1.440000e+05  5.185620e+05   \n",
      "75%                NaN      1.000000      2.025000e+05  8.086500e+05   \n",
      "max                NaN     11.000000      9.000000e+06  3.375000e+06   \n",
      "\n",
      "          AMT_ANNUITY  AMT_GOODS_PRICE  ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
      "count    19998.000000     1.997800e+04  ...     20000.000000     20000.000000   \n",
      "unique            NaN              NaN  ...              NaN              NaN   \n",
      "top               NaN              NaN  ...              NaN              NaN   \n",
      "freq              NaN              NaN  ...              NaN              NaN   \n",
      "mean     27065.465122     5.378249e+05  ...         0.007850         0.000450   \n",
      "std      14388.402834     3.707560e+05  ...         0.088254         0.021209   \n",
      "min       1615.500000     4.500000e+04  ...         0.000000         0.000000   \n",
      "25%      16573.500000     2.385000e+05  ...         0.000000         0.000000   \n",
      "50%      24918.750000     4.500000e+05  ...         0.000000         0.000000   \n",
      "75%      34587.000000     6.795000e+05  ...         0.000000         0.000000   \n",
      "max     208215.000000     3.375000e+06  ...         1.000000         1.000000   \n",
      "\n",
      "       FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
      "count       20000.00000      20000.00000               17299.000000   \n",
      "unique              NaN              NaN                        NaN   \n",
      "top                 NaN              NaN                        NaN   \n",
      "freq                NaN              NaN                        NaN   \n",
      "mean            0.00025          0.00025                   0.006474   \n",
      "std             0.01581          0.01581                   0.085778   \n",
      "min             0.00000          0.00000                   0.000000   \n",
      "25%             0.00000          0.00000                   0.000000   \n",
      "50%             0.00000          0.00000                   0.000000   \n",
      "75%             0.00000          0.00000                   0.000000   \n",
      "max             1.00000          1.00000                   3.000000   \n",
      "\n",
      "        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
      "count                17299.000000                17299.000000   \n",
      "unique                        NaN                         NaN   \n",
      "top                           NaN                         NaN   \n",
      "freq                          NaN                         NaN   \n",
      "mean                     0.005723                    0.032198   \n",
      "std                      0.094487                    0.189788   \n",
      "min                      0.000000                    0.000000   \n",
      "25%                      0.000000                    0.000000   \n",
      "50%                      0.000000                    0.000000   \n",
      "75%                      0.000000                    0.000000   \n",
      "max                      5.000000                    6.000000   \n",
      "\n",
      "        AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
      "count                17299.000000               17299.000000   \n",
      "unique                        NaN                        NaN   \n",
      "top                           NaN                        NaN   \n",
      "freq                          NaN                        NaN   \n",
      "mean                     0.261402                   0.255853   \n",
      "std                      0.895381                   0.601939   \n",
      "min                      0.000000                   0.000000   \n",
      "25%                      0.000000                   0.000000   \n",
      "50%                      0.000000                   0.000000   \n",
      "75%                      0.000000                   0.000000   \n",
      "max                     19.000000                   8.000000   \n",
      "\n",
      "        AMT_REQ_CREDIT_BUREAU_YEAR  \n",
      "count                 17299.000000  \n",
      "unique                         NaN  \n",
      "top                            NaN  \n",
      "freq                           NaN  \n",
      "mean                      1.891034  \n",
      "std                       1.873802  \n",
      "min                       0.000000  \n",
      "25%                       0.000000  \n",
      "50%                       1.000000  \n",
      "75%                       3.000000  \n",
      "max                      17.000000  \n",
      "\n",
      "[11 rows x 68 columns]\n",
      "TARGET\n",
      "0    18451\n",
      "1     1549\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Expect the file to be in the same folder as this notebook\n",
    "df = pd.read_csv('Case_Data.csv' )\n",
    "print(df.shape)\n",
    "print(df.describe(include='all'))\n",
    "print(df['TARGET'].value_counts())# summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2adaa2",
   "metadata": {},
   "source": [
    "## Step 1: Partition our Data and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da51701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14000, 165), (6000, 165))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn categorical variables into dummy (0/1) columns\n",
    "X = pd.get_dummies(df.drop(columns=[\"TARGET\"]), drop_first=True)  \n",
    "\n",
    "# Target variable\n",
    "Y = df[\"TARGET\"]\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    test_size=0.3,     # 30% test, 70% train\n",
    "    random_state=99,   # reproducibility\n",
    "    shuffle=True       # shuffle before splitting\n",
    ")\n",
    "\n",
    "# Check shapes\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a394d09",
   "metadata": {},
   "source": [
    "## Step 2 â€” Train/ Fit Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d681466b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine classes and ordering\n",
    "classes = pd.unique(pd.Series(Y_train).dropna())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fa648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 0,1 for XGBoost \n",
    "mapping = {c: int(c == 1) for c in classes}\n",
    "\n",
    "Y_train = pd.Series(Y_train).map(mapping).to_numpy()\n",
    "Y_test = pd.Series(Y_test).map(mapping).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) CV split (same as before)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "\n",
    "# 3) Pipeline with XGBoost model\n",
    "xgb_pipe = Pipeline([\n",
    "    (\"model\", XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_jobs=-1,          # use all cores\n",
    "        eval_metric=\"auc\",  # pairs well with scoring=\"roc_auc\"\n",
    "        tree_method=\"hist\", # fast CPU histogram algorithm (use \"gpu_hist\" if you have a GPU)\n",
    "        random_state=99\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4) Hyperparameter grid (reasonable, compact search)\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [400, 800],\n",
    "    \"model__max_depth\":    [4, 6, 8],\n",
    "    \"model__learning_rate\":[0.05, 0.1],\n",
    "    \"model__subsample\":    [0.8, 1.0],\n",
    "    \"model__colsample_bytree\": [0.8, 1.0],\n",
    "    \"model__min_child_weight\": [1, 3]\n",
    "}\n",
    "\n",
    "# 5) Cross-validated grid search (same scoring)\n",
    "xgb_cv = GridSearchCV(\n",
    "    estimator=xgb_pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# 6) Fit with per-sample weights\n",
    "xgb_cv.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Positive class used by AUC:\", xgb_cv.best_estimator_.named_steps[\"model\"].classes_[1])\n",
    "print(\"Best params selected by CV:\", xgb_cv.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", round(xgb_cv.best_score_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf099d36",
   "metadata": {},
   "source": [
    "### Now determine feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best fitted model from GridSearchCV\n",
    "best_xgb = xgb_cv.best_estimator_.named_steps[\"model\"]\n",
    "\n",
    "# Get feature importances (aligned with columns of X_train)\n",
    "importances = best_xgb.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Put in DataFrame for clarity\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(feat_imp.head(15))  # top 15 features\n",
    "\n",
    "# Optional: plot top features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "feat_imp.head(15).plot(kind=\"barh\", x=\"feature\", y=\"importance\", legend=False)\n",
    "plt.title(\"Top 15 Random Forest Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f566c9",
   "metadata": {},
   "source": [
    "## Step 3: Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine class order of your response variable\n",
    "classes = xgb_cv.best_estimator_.named_steps[\"model\"].classes_\n",
    "print(\"Class order:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594afd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_idx = list(classes).index(1)   #Put in the class you are trying to predict\n",
    "proba = xgb_cv.predict_proba(X_test)[:, pos_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb53a12",
   "metadata": {},
   "source": [
    "## Step 4: Calculate test set ROC/AUC using predicted probabilities from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b84b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve + AUC (tell roc_curve which label is positive)\n",
    "pos_label=1 \n",
    "fpr, tpr, _ = roc_curve(Y_test, proba, pos_label=pos_label)\n",
    "roc_auc = roc_auc_score((Y_test == pos_label).astype(int), proba)\n",
    "print(f\"ROC AUC (test): {roc_auc:.3f}\")\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Random Forest)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ticket_UI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
